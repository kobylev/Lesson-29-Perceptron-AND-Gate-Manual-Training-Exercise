# Manual Learning of AND Gate Using a Perceptron

## Assignment Description

This assignment requires **manual** implementation of learning an AND logic gate using a single perceptron, using the iteration method (perceptron algorithm / gradient descent), **not** through analytical solution of a system of equations.

## Perceptron Architecture

The perceptron consists of:
- **One neuron**
- **Three inputs:**
  - X‚ÇÄ = 1 (bias)
  - X‚ÇÅ (first input)
  - X‚ÇÇ (second input)
- **Three weights:**
  - W‚ÇÄ (bias weight)
  - W‚ÇÅ
  - W‚ÇÇ
- **Activation function:** sign
  - Negative output ‚Üí 0 (False)
  - Positive output ‚Üí 1 (True)

## Dataset - AND Gate

| X‚ÇÄ | X‚ÇÅ | X‚ÇÇ | Y (target) |
|:--:|:--:|:--:|:----------:|
| 1  | 0  | 0  |     0      |
| 1  | 0  | 1  |     0      |
| 1  | 1  | 0  |     0      |
| 1  | 1  | 1  |     1      |

## Workflow

### 1. Initialize Weights
Start with random weights (any legitimate starting set is valid).  
For example: W‚ÇÄ = 0.5, W‚ÇÅ = -0.3, W‚ÇÇ = 0.2

### 2. Training Loop
Iterate through the examples **one by one** (batch size = 1):

For each example, perform:

1. **Calculate the dot product:**
   ```
   z = W‚ÇÄ¬∑X‚ÇÄ + W‚ÇÅ¬∑X‚ÇÅ + W‚ÇÇ¬∑X‚ÇÇ = W·µÄ¬∑X
   ```

2. **Apply the sign function:**
   ```
   ≈∑ = sign(z) = { 1  if z ‚â• 0
                 { 0  if z < 0
   ```

3. **Calculate the error:**
   ```
   error = Y - ≈∑
   ```

4. **Update weights** (perceptron algorithm):
   ```
   W‚ÇÄ ‚Üê W‚ÇÄ + Œ∑ ¬∑ error ¬∑ X‚ÇÄ
   W‚ÇÅ ‚Üê W‚ÇÅ + Œ∑ ¬∑ error ¬∑ X‚ÇÅ
   W‚ÇÇ ‚Üê W‚ÇÇ + Œ∑ ¬∑ error ¬∑ X‚ÇÇ
   ```
   Where Œ∑ (learning rate) is typically = 1 in the classical perceptron algorithm

### 3. Stopping Criterion
Continue until all four examples are correctly classified (100% accuracy).

**Note:** One epoch = one complete pass through all four examples.

## Submission Requirements

### Allowed Tools
**Only** one of the following:
- ‚úèÔ∏è **Manual:** Pen and paper
- üìä **Digital:** Microsoft Excel

### Submission Format
- **PDF file only**
  - Manual work ‚Üí Scan/photograph clearly and convert to PDF
  - Excel work ‚Üí Export the spreadsheet to PDF
- Upload to the course repository

## What to Include in the Document

### 1. Network Architecture Diagram ‚úÖ
A manual drawing/diagram including:
- One neuron
- Three inputs: X‚ÇÄ=1, X‚ÇÅ, X‚ÇÇ
- Weights: W‚ÇÄ, W‚ÇÅ, W‚ÇÇ
- One output after the sign function

### 2. Data Table ‚úÖ
Clear presentation of the four AND gate examples

### 3. Iteration Table ‚úÖ
For each update step, document:
- Iteration number
- Current weights (W‚ÇÄ, W‚ÇÅ, W‚ÇÇ)
- Current input vector (X‚ÇÄ, X‚ÇÅ, X‚ÇÇ)
- Dot product (z)
- Output after sign (≈∑)
- Target (Y)
- Error
- Updated weights

### 4. Process Documentation ‚úÖ
- Document all iterations until convergence
- Specify how many epochs were required
- Show that you achieved 100% correct classification

## Example Table Structure

| Iteration | W‚ÇÄ | W‚ÇÅ | W‚ÇÇ | X‚ÇÄ | X‚ÇÅ | X‚ÇÇ | z | ≈∑ | Y | Error | W‚ÇÄ' | W‚ÇÅ' | W‚ÇÇ' |
|:---------:|:--:|:--:|:--:|:--:|:--:|:--:|:-:|:-:|:-:|:-----:|:---:|:---:|:---:|
| 1 | 0.5 | -0.3 | 0.2 | 1 | 0 | 0 | 0.5 | 1 | 0 | -1 | ... | ... | ... |
| 2 | ... | ... | ... | 1 | 0 | 1 | ... | ... | 0 | ... | ... | ... | ... |

## Tips for Success

1. üéØ **Choose simple initial weights** - prefer small numbers (-1 to 1)
2. üìù **Work in order** - start from the first example in each epoch
3. ‚úîÔ∏è **Check each calculation** - calculation errors will lead to non-convergence
4. üîÅ **Patience** - may require 2-3 epochs or more
5. üìã **Legibility** - ensure handwriting/spreadsheet is clear and readable

## Frequently Asked Questions

**Q: What learning rate should I use?**  
A: In the classical perceptron algorithm, use Œ∑=1

**Q: What if it doesn't converge?**  
A: The AND gate is linearly separable - if you followed the method correctly, it must converge

**Q: Can I use Python?**  
A: No! Only manual or Excel

**Q: How many iterations are expected?**  
A: Depends on initial weights - typically 4-20 iterations

---

**Good luck! üöÄ**